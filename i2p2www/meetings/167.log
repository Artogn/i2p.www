{% extends "_layout.html" %}
{% block title %}I2P Development Meeting 167{% endblock %}
{% block content %}<h3>I2P dev meeting, February 7, 2005</h3>
<div class="irclog">
15:36 < jrandom> 0) hi</p>
15:36 < jrandom> 1) Net status</p>
15:36 < jrandom> 2) _PRE net progress</p>
15:36 < jrandom> 3) I2Phex 0.1.1.37</p>
15:36 < jrandom> 4) ???</p>
15:36 < jrandom> 0) hi</p>
15:37  * jrandom waves</p>
15:37 < jrandom> weekly status notes posted up @ http://dev.i2p.net/pipermail/i2p/2006-February/001258.html</p>
15:37 < bar> hello</p>
15:38 < jrandom> while y'all dig through that oh-so-exciting material, lets jump on in to 1) Net status</p>
15:38 < jrandom> there hasn't been much changed on the live net in the last week, from an i2p perspective, so I don't really have much to add here</p>
15:39 < jrandom> anyone have anything they want to bring up regarding the current net status?</p>
15:39 < KBlup> I have seen terrible spikes of failing clients when running i2p for long... dunno if thats fits to 1)</p>
15:39 < jrandom> KBlup: does that correlate to high cpu load or bandwidth consumption?</p>
15:40 < KBlup> resuluts in msg-delay &gt; 10000ms :-/</p>
15:40 < jrandom> ah, very likely one of the causes of the _PRE net being developed :)</p>
15:40 < KBlup> I think it then tries to establish new tunnels and fails constantly, which results in 300+ jobs some times...</p>
15:41 < KBlup> my maschine is quite strong but overloaded with that...</p>
15:41 < jrandom> aye, thats all been reworked along the way for 0.6.1.10, hang tight until thats ready</p>
15:43 < jrandom> ok, anything else on 1), or shall we mosey on over to 2) _PRE net progress</p>
15:43 <+Complication> 0.6.1.10 seems to contain substantial changed indeed</p>
15:45 < jrandom> yeah, there's a lot of meat under here.  The current state is that the new creation code is in place and seems to be working properly, but now I'm using this opportunity to debug some of the underlying issues further</p>
15:46 <+Complication> You mentioned having to cough up a lot of CPU time in advance</p>
15:47 <+Complication> Would this cost now be associated with building any sort of a tunnel?</p>
15:48 <+Complication> (meaning, before the construction, during a short while, you'd have to perform a batch of heavy crypto)</p>
15:48 < jrandom> yes, all tunnel build requests will need to do k heavy crypto operations (where k = number of hops in the tunnel being built)</p>
15:49 <+Complication> Whad I wanted to ask... is the interval just tighter than before, or the amount bigger too?</p>
15:50 < jrandom> the amount is both bigger, smaller, and tighter.  tighter, in that they're all done upfront.  bigger, in that we can't short circuit and not do the encryption for a hop if an earlier hop rejects it, and smaller in that earlier hops fail a lot less</p>
15:51 < jrandom> in addition, however, unlike earlier releases, we're no longer using ElGamal/AES+SessionTag for the tunnel requests - we use (fairly) straight ElGamal</p>
15:52 <+Complication> ...and it couldn't be pre-calculated, unless one knew the final set that's going to succeed?</p>
15:52 < jrandom> that means that while we used to be able to cheat without an asymmetric operation, we don't try to cheat anymore (as the cheating itself exposed a class of attacks)</p>
15:53 <+Complication> (set of peers)</p>
15:53 < jrandom> hmm, it could certainly be precalculated, assuming you know who the peers in the tunnel that are going to be asked</p>
15:54 < jrandom> the new tunnel creation process is done on a separate thread, so it doesn't bog down the main job queue under load, and so that it can throttle itself better</p>
15:54 <+Complication> Could one also assume that, barring change in available knowledge, one knows a few whom one is going to ask from, if attempts fail?</p>
15:54 < jrandom> hmm, not entirely sure I follow</p>
15:55 <+Complication> Or is knowing them already useless, since the struct must be redone from scratch?</p>
15:56 <+Complication> (meaning: the ElGamals redone from scratch, at least)</p>
15:56 < jrandom> ah, the structure is http://dev.i2p.net/cgi-bin/cvsweb.cgi/i2p/router/doc/tunnel-alt-creation.html?rev=HEAD#tunnelCreate.requestRecord</p>
15:56 < jrandom> so, yes, if the next hop changes, the ElGamal must be redone</p>
15:56 < jrandom> (if you precompute)</p>
15:56 <+Complication> Right, I wasn't sure enough about that instantly</p>
15:57 <+Complication> Now I realize it, though</p>
15:57 < jrandom> otoh, we're really trying to get our build success rate up, and the new build process should be able to adapt to minimize unnecessary creations</p>
15:58 <+Complication> How does it seem doing in reality?</p>
15:58 < jrandom> (oh, that structure has been slightly modified on the _PRE branch: http://dev.i2p.net/cgi-bin/cvsweb.cgi/~checkout~/i2p/router/doc/tunnel-alt-creation.html?rev=1.1.2.1;content-type=text%2Fhtml#tunnelCreate.requestRecord )</p>
15:59 <+Complication> I noticed the detail about ElGamal encrypts taking a leap towards quickness...</p>
15:59 < jrandom> well, the build success rate is much much higher than it is on the live net, but that may just be due to the small _PRE net size</p>
16:00 < jrandom> yeah, creating a 2 hop structure, for instance, takes an average of 44ms over 1120 runs, as compared to the live net's ElGamal encryption time of 542ms (over 1344 runs)</p>
16:02 < jrandom> (on the same box)</p>
16:02 <+Complication> Would this 542 include retries on failure too, or just the pure building?</p>
16:02 <+Complication> If it's pure building, I need to find my lower jaw... it's on the floor somewhere. :P</p>
16:02 < KBlup> about that change of the exponent : at what scale does that affect anonymity?</p>
16:02 < jrandom> no, thats the pure elGamal stat, since the live net doesn't build the new _PRE net structure</p>
16:04 < jrandom> KBlup: anonymity?  none.  security?  according to what I've read, 228 bits is more than enough to match 2048bit ElGamal</p>
16:04  * Complication doesn't know much about ElGamal's x and y</p>
16:04 <+Complication> Not enough to comment meaninfully</p>
16:06 <+Complication> If serious researchers consider the shorter x hard enough, and those crypto wonks didn't run away screaming...</p>
16:06 <@cervantes> well not only that, but the implications of dropping to 1024/160</p>
16:07 < KBlup> i guess i have to read the paper later ;)</p>
16:07 <+Complication> cervantes: yes, it's better than that, for sure</p>
16:08 <+Complication> Besides, what is the foremost attack this cipher must repel, and how long is the attack viable?</p>
16:09 <+Complication> Could it be something which benefits you only if you break it quick, or also benefits if you break it eventually?</p>
16:11 <+Complication> If I understand right, the immediate secret it guards is the next tunnel participant, right?</p>
16:11 <+Complication> (or more precisely, the next-to-next one)</p>
16:11 <@modulus> meeting ongoing?</p>
16:11 <+Complication> (which only the next one may know)</p>
16:11 <@cervantes> modulus: ayre</p>
16:11 <@cervantes> -r</p>
16:11 < jrandom> for a practical (yet insanely powerful) adversary, breaking it during the tunnel lifetime would be necessary.  breaking it after that tunnel lifetime would only help if you logged all network traffic and broke all tunnels (that is, after breaking the ephemeral transport layer crypto and working on the tunnel layer crypto)</p>
16:11 < jrandom> so, we're talking on the order of minutes here, not decades</p>
16:12 < jrandom> (so 1024bit is probably even overkill)</p>
16:12 <@cervantes> is there a way to measure the risk in a meaningful way?</p>
16:13 <+Complication> Besides, for a tunnel with more hops, the adversary would have to break several, right?</p>
16:13 <+Complication> (though the builder would have to build several too)</p>
16:13 <@cervantes> if we need no more than 1024 bits, then is it really necessary to use more? </p>
16:14 <@cervantes> we can always use a stronger algo in 3 years time when we've got vastly more powerful quantum computers</p>
16:14 <@modulus> jrandom: if the adversary would know that at time hh:mm something important is going to be tunneled is it likely they could break it somehow by logging?</p>
16:14 < jrandom> Complication: right, they'd have to break several (and the DH keys protecting the transport layer)</p>
16:14 <@modulus> afaik 1024bit is break()able with a lot of power</p>
16:15 < jrandom> a lot of power and a decade</p>
16:15 < jrandom> (or three)</p>
16:15 <@cervantes> jrandom: is it difficult to try the weaker cipher?</p>
16:15 <@modulus> i was under the impression that 1024bit composits were factorizable these days in a few months.</p>
16:15 <@cervantes> could we roll out to the pre net </p>
16:15 <@cervantes> and see whether it actually offers much benefit</p>
16:16 <@cervantes> modulus: yes but they'd need to break several</p>
16:16 <@modulus> if this is based on discrete log domain and all that stuff then i don't know anything</p>
16:16 <@modulus> cervantes: aha</p>
16:16 < jrandom> cervantes: it requires changes to a lot of structures, since we currently use 512byte slots.  though, perhaps we could just fill the first 256 bytes with 0x00 for testing</p>
16:17 < jrandom> modulus: ElGamal is based on discrete log</p>
16:17 <@cervantes> jrandom: worthy of testing?</p>
16:17 <@modulus> right right, i was imagining RSA</p>
16:17 <@cervantes> or better to focus on other things and return to it if necessary</p>
16:18 < jrandom> definitely worth testing, though for the moment I'm hacking away at some transport layer evaluations</p>
16:18 <+Complication> I guess it depends on how their calculation can be handled in real life.</p>
16:18 < jrandom> (and the 44ms encryption time is good enough for the moment, though a 4ms encryption time would be even better :)</p>
16:19 <+Complication> If it holds together with current computers, it will improve with newer machines.</p>
16:19 <@modulus> especially if there comes crypto hw, as it is starting to come in some</p>
16:19 < jrandom> but, of course, changing this parameter will not be done lightly or immediately.  but if someone has a good reason to avoid it, please get in touch</p>
16:21 < jrandom> modulus: I've heard of dedicated AES and RSA chips, but nothing on DH/ElGamal.  otoh, when one looks to the NSA/etc as an adversary, where they can build their own, its possible</p>
16:22 <@cervantes> they have crypto machines built on ring sprinkled donut technology</p>
16:23  * Complication is willing to upgrade the Celeron 300 to Athlon 600, if it holds the tide of ring-sprinkled donuts :D</p>
16:23 < tethra> heheh</p>
16:24 < jrandom> mmMMmm donuts</p>
16:25 < jrandom> ok, anyone have anything else on 2) _PRE net progress?</p>
16:25 < jrandom> if not, lets jump on over to 3) I2Phex 0.1.1.37</p>
16:26 < jrandom> Complication: wanna give us the skinny?</p>
16:26 <+Complication> Well, it seems to work. :)</p>
16:26 <+Complication> There is hope of getting more webcaches for extra redundancy soon.</p>
16:27 < jrandom> word</p>
16:27 < jrandom> hmm, do you think we need more webcaches?  don't we just need one to be up?  not that more hurts, of course</p>
16:27 <+Complication> (if legion manages to solve the mysteries which haunted his initial try)</p>
16:27 <+Complication> There's also a mystery bug in there, but it doesn't byte hard, and I'm trying to find it.</p>
16:28 <+Complication> One up is enough</p>
16:28 <+Complication> More just increases the chances that one is up</p>
16:28 < jrandom> cool</p>
16:28 <+Complication> Because at current stage, it will never drop webcaches as bad. Too few of them altogether.</p>
16:29 <+Complication> (that routine will activate if there exist more than 10)</p>
16:29 <+Complication> (if I remember correctly)</p>
16:29 <+Complication> As for the bug: after a long time operating, the webcache subsystem sometimes stalls</p>
16:30 <+Complication> Likely because a httpclient's GET request can't be aborted successfully</p>
16:31 <@modulus> so it needs to die from time to time?</p>
16:31 <+Complication> It's safe, and never seems to bite freshly joined machines</p>
16:31 < jrandom> hmm, what does that mean, functionally?  after a while, it will stop registering with the webcache, so new people won't be given references to them?</p>
16:31 <+Complication> If it bites a machine already well integrated, that machine can get enough peers from the peers it's already connected to</p>
16:31 <+Complication> So currently the impact seems close to 0</p>
16:31 <@modulus> cool</p>
16:32 <+Complication> It's curious, just</p>
16:32 <@modulus> no rule about when it will fail or anything?</p>
16:32 <+Complication> modulus: generally not before 20 hours</p>
16:33 <+Complication> And since I have no way of forcing it to occur, debugging is a bit slow</p>
16:33 <@modulus> :_)</p>
16:34 <+Complication> Either way, should I find it, I'll fix it, and should I not find it, I'll find other stuff to tinker with :)</p>
16:34 < jrandom> :)</p>
16:34 < jrandom> sounds like its just a symptom of some bugs we've seen in the streaming lib / eepproxy, so fixing those should fix this</p>
16:35 <+Complication> Could be</p>
16:38 < jrandom> ok great, nice work Complication</p>
16:38 < jrandom> anyone have anything else on 3) I2Phex 0.1.1.37, or shall we jump on over to the catch-all, 4) ???</p>
16:41 < jrandom> (consider us jumped)</p>
16:41 < jrandom> ok, anyone have anything else for the meeting?</p>
16:42 < tmp> Or forever hold your breath?</p>
16:43 < jrandom> and ever and ever</p>
16:43  * jrandom winds up</p>
16:43  * jrandom *baf*s the meeting closed</p>
</div>
{% endblock %}